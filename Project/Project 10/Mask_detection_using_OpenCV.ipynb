{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mask detection using OpenCV.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "A764c7pru1Xf"
      },
      "source": [
        "from keras.optimizers import RMSprop\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import cv2\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Input, ZeroPadding2D, BatchNormalization, Activation, MaxPooling2D, Flatten, Dense,Dropout\n",
        "from keras.models import Model, load_model\n",
        "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.utils import shuffle\n",
        "import imutils\n",
        "import numpy as np"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hjZa4Nqu91X"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator,array_to_img,img_to_array,load_img\n",
        "import matplotlib as mt\n",
        "train_datagen=ImageDataGenerator()\n",
        "\n",
        "test_datagen= ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8asAzn_IP75"
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqiJbq8rIexa",
        "outputId": "5a163fb2-bee7-43a8-bff3-2c9f166b3b35"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2TiVVupLBbO",
        "outputId": "5c939676-1e7d-4f11-fe4c-4f92406d1294"
      },
      "source": [
        "!ls = '/content/drive/MyDrive/data'"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ls: cannot access '=': No such file or directory\n",
            "/content/drive/MyDrive/data:\n",
            "test  train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q22srTr0u-BB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49ee630c-6a01-40ec-a99f-12c08979dcf0"
      },
      "source": [
        "import cv2,os\n",
        "\n",
        "batch_size=10\n",
        "train_data=train_datagen.flow_from_directory(\n",
        "'/content/drive/MyDrive/data/train/',\n",
        "target_size=(150,150),\n",
        "batch_size=batch_size,\n",
        "class_mode='binary')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1315 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeZFDJ3-u-C-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0380127d-13dd-4b31-c6c8-de554733ca8c"
      },
      "source": [
        "test_data=test_datagen.flow_from_directory(\n",
        "'/content/drive/MyDrive/data/test/',\n",
        "target_size=(150,150),\n",
        "batch_size=batch_size,\n",
        "class_mode='binary')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 194 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWdiZk6su-Gv"
      },
      "source": [
        "from keras.models import Sequential\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(100, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    MaxPooling2D(2,2),\n",
        "    \n",
        "    Conv2D(100, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2,2),\n",
        "    \n",
        "    Flatten(),\n",
        "    Dropout(0.5),\n",
        "    Dense(50, activation='relu'),\n",
        "    Dense(2, activation='softmax')\n",
        "])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1WFl859u-IX"
      },
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9XEkRBju-MA"
      },
      "source": [
        "checkpoint = ModelCheckpoint('model2-{epoch:03d}.model',monitor='val_loss',\n",
        "                             verbose=0,save_best_only=True,mode='auto')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgJi3XaRu-NW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79ba4879-ed01-44d5-e5f4-0a5cc1eca3f0"
      },
      "source": [
        "histroy=model.fit_generator(train_data,steps_per_epoch=50//batch_size,epochs=10,\n",
        "                             validation_data=test_data,validation_steps=40//batch_size)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1915: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "5/5 [==============================] - 35s 4s/step - loss: 160.5168 - acc: 0.7178 - val_loss: 0.7356 - val_acc: 0.4250\n",
            "Epoch 2/10\n",
            "5/5 [==============================] - 18s 4s/step - loss: 29.7140 - acc: 0.4017 - val_loss: 0.6935 - val_acc: 0.4250\n",
            "Epoch 3/10\n",
            "5/5 [==============================] - 15s 3s/step - loss: 0.8174 - acc: 0.6514 - val_loss: 0.6931 - val_acc: 0.5500\n",
            "Epoch 4/10\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.7911 - acc: 0.3275 - val_loss: 0.6936 - val_acc: 0.3500\n",
            "Epoch 5/10\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6470 - acc: 0.5683 - val_loss: 0.6933 - val_acc: 0.5000\n",
            "Epoch 6/10\n",
            "5/5 [==============================] - 10s 2s/step - loss: 0.6498 - acc: 0.5836 - val_loss: 0.6916 - val_acc: 0.6500\n",
            "Epoch 7/10\n",
            "5/5 [==============================] - 11s 2s/step - loss: 0.9938 - acc: 0.6011 - val_loss: 0.6924 - val_acc: 0.5500\n",
            "Epoch 8/10\n",
            "5/5 [==============================] - 10s 2s/step - loss: 0.7101 - acc: 0.5372 - val_loss: 0.6946 - val_acc: 0.4000\n",
            "Epoch 9/10\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.5478 - acc: 0.6994 - val_loss: 0.6908 - val_acc: 0.6000\n",
            "Epoch 10/10\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.5863 - acc: 0.5856 - val_loss: 0.6932 - val_acc: 0.5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEKNCAJGu-Qe"
      },
      "source": [
        "model.save('mask_project.h5')"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7m33-pPYu-TV"
      },
      "source": [
        "import tensorflow as tf\n",
        "model = tf.keras.models.load_model('mask_project.h5')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVFQtOIzve22"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "model = tf.keras.models.load_model('mask_project.h5')\n",
        "\n",
        "results={0:'without mask',1:'mask'}\n",
        "GR_dict={0:(0,0,255),1:(0,255,0)}\n",
        "\n",
        "rect_size = 4\n",
        "cap = cv2.VideoCapture(0) \n",
        "\n",
        "\n",
        "haarcascade = cv2.CascadeClassifier('E:/STUDY MATEIALS/LetsUpgrade/Project/Face Mask Detection/haarcascade_frontalface_default.xml')\n",
        "\n",
        "while True:\n",
        "    (rval, im) = cap.read()\n",
        "    im=cv2.flip(im,1,1) \n",
        "\n",
        "    \n",
        "    rerect_size = cv2.resize(im, (im.shape[1] // rect_size, im.shape[0] // rect_size))\n",
        "    faces = haarcascade.detectMultiScale(rerect_size)\n",
        "    for f in faces:\n",
        "        (x, y, w, h) = [v * rect_size for v in f] \n",
        "        \n",
        "        face_img = im[y:y+h, x:x+w]\n",
        "        rerect_sized=cv2.resize(face_img,(150,150))\n",
        "        normalized=rerect_sized/255.0\n",
        "        reshaped=np.reshape(normalized,(1,150,150,3))\n",
        "        reshaped = np.vstack([reshaped])\n",
        "        result=model.predict(reshaped)\n",
        "\n",
        "        \n",
        "        label=np.argmax(result,axis=1)[0]\n",
        "      \n",
        "        cv2.rectangle(im,(x,y),(x+w,y+h),GR_dict[label],2)\n",
        "        cv2.rectangle(im,(x,y-40),(x+w,y),GR_dict[label],-1)\n",
        "        cv2.putText(im, results[label], (x, y-10),cv2.FONT_HERSHEY_SIMPLEX,0.8,(255,255,255),2)\n",
        "\n",
        "    cv2.imshow('LIVE',   im)\n",
        "    key = cv2.waitKey(10)\n",
        "    \n",
        "    if key == 27: \n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8V4KGe03vmMO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}